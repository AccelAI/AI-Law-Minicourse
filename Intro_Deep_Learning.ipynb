{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](./images/DL-NLP-intro.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Agenda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- What is Deep Learning?\n",
    "- The Rise of Deep Learning\n",
    "- Convolutional Neural Networks\n",
    "- Deep Learning for NLP\n",
    "- Homework Review & Troubleshooting\n",
    "- Assesment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Ng](./images/Ng-quote.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning\n",
    "\n",
    "![brain-network](https://ville.montreal.qc.ca/idmtl/en/wp-content/uploads/sites/2/2017/04/inf2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Mimics the neocortex of our brains\n",
    "\n",
    "![](https://media.nature.com/full/nature-assets/neuro/journal/v19/n3/images/nn.4244-F1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Deep-learning software attempts to mimic the activity in layers of neurons in the neocortex, the wrinkly 80 percent of the brain where thinking occurs. The software learns, in a very real sense, to recognize patterns in digital representations of sounds, images, and other data.\n",
    "\n",
    "The basic idea—that software can simulate the neocortex’s large array of neurons in an artificial “neural network”—is decades old, and it has led to as many disappointments as breakthroughs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](http://www.nlpacademy.co.uk/images/uploads/whatisnlp.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Perceptron = Single Layer\n",
    "\n",
    "![](./images/perceptron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The neurons in our brain transmitting these electrochemical signals have inspired the artificial neuron called a perceptron.\n",
    "\n",
    "Perceptrons are one of the earliest algorithms used for classification in supervised learning - with only a single layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Input > Classifier > Output\n",
    "![](./images/classifiers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Classification - categorize a group of objects while only using some basic data features to describe them in order to predict a value.\n",
    "\n",
    "This is done by building a model based on one or more numerical or categorical variables (predictors, attributes, or features). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ML vs DL\n",
    "- Most current machine learning works\twell because of\thuman-designed representations and\tinput\tfeatures\t\n",
    "- Machine learning becomes just\t optimizing\tweights\tto\tbest make a\tfinal prediction\t\n",
    "- Representation\tlearning\tattempts\tto automatically learn\tgood features or representations\t\n",
    "- Deep learning algorithms attempt to\tlearn multiple\tlevels\tof\trepresentation\tof\tincreasing\tcomplexity/abstraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Classifiers\n",
    "\n",
    "![](./images/linear-classifiers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Regression vs Classification\n",
    "\n",
    "The simplest version of a classifier in ML is linear regression. \n",
    "\n",
    "The formula for a straight line is y=mx+b. Where x is the input, m is the slope of the line, b is the y-intercept, and y is the output for that position of x.\n",
    "\n",
    "The values we have available to adjust or train are m and b, where m is the slope and b is the y intercept. There is no other way to affect the variables of the line, since all that is left is our input and our output. \n",
    "\n",
    "In machine learning there are many M’s since there may be many features. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](./images/weights-biases.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The collection of these values is formed into a matrix that is denoted (W) for the weights matrix.\n",
    "The b’s are arranged together for the biases.\n",
    "\n",
    "The prediction accuracy of a neural net depends on its weights and biases. \n",
    "\n",
    "Each iteration or cycle of updating the weights and biases (improving accuracy) is called one training step.\n",
    "\n",
    "Each edge has a unique weight and each weight has a unique bias - this means the combination for each is also unique, which explains why the nodes fire differently. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A neural network = running several logistic regressions at the same time\n",
    "\n",
    "![neural net](https://cdn-images-1.medium.com/max/1600/0*IUWJ5oJ_z6AiG7Ja.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "If\twe\tfeed a vector\tof\tinputs\tthrough\ta\tbunch\tof\tlogistic regression\tfunctions,\tthen\twe\tget\ta\tvector of outputs....\n",
    "\n",
    "- which\twe can\tfeed into another logistic regression function\n",
    "- It is the training criterion that will direct what the intermediate hidden variables should be,\tso as to do\ta good job at predicting the targets for the next layer, etc.\t\n",
    "- Before we\tknow it, we\thave a multilayer neural network…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Rise of Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Why Now?\n",
    "\n",
    "Despite prior investigation and understanding of many of the algorithmic techniques …\n",
    "Before 2006 training deep architectures was unsuccessful.\n",
    "\n",
    "### What has changed?\n",
    "- Faster machines and more data help DL more than other algorithms\n",
    "- New methods for unsupervised pre-training have been developed\n",
    "- More efficient parameter estimation methods\n",
    "- Better understanding of model regularization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://cdn-images-1.medium.com/max/2000/1*3IXgb4fIFFJbIOgMzl9RGA.jpeg)\n",
    "\n",
    "Jensen Huang, NVIDIA CEO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://image.slidesharecdn.com/introductiontomulti-gpudeeplearningwithdigits2-mikewang-150820102631-lva1-app6891/95/introduction-to-multi-gpu-deep-learning-with-digits-2-mike-wang-22-638.jpg?cb=1440074781)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Deep Learning in the Cloud\n",
    "\n",
    "![](https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2015/11/nvidia-deep-learning.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Neural Networks (CNNs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What is a Convolution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](./images/cnn-artithmetic.gif)\n",
    "\n",
    "Source: https://github.com/vdumoulin/conv_arithmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The arithmetic being performed can be thought of as a spotlight - extracting features, such as edges, from an image one layer at a time. These layers are often called filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](./images/convolution-schematic.gif)\n",
    "\n",
    "Convolution with 3×3 Filter. Source: http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "For me easiest way to understand a convolution is by thinking of it as a sliding window function applied to a matrix. That’s a mouthful, but it becomes quite clear looking at a visualization.\n",
    "\n",
    "Imagine that the matrix on the left represents an black and white image. Each entry corresponds to one pixel, 0 for black and 1 for white (typically it’s between 0 and 255 for grayscale images). The sliding window is called a kernel, filter, or feature detector. Here we use a 3×3 filter, multiply its values element-wise with the original matrix, then sum them up. To get the full convolution we do this for each element by sliding the filter over the whole matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What are Convolutional Neural Networks?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://www.mathworks.com/content/mathworks/www/en/discovery/convolutional-neural-network/jcr:content/mainParsys/image_copy.adapt.full.high.jpg/1508999490138.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "CNNs are basically just several layers of convolutions with nonlinear activation functions like ReLU or tanh applied to the results. In a traditional feedforward neural network we connect each input neuron to each output neuron in the next layer. That’s also called a fully connected layer, or affine layer. In CNNs we don’t do that. Instead, we use convolutions over the input layer to compute the output. This results in local connections, where each region of the input is connected to a neuron in the output. Each layer applies different filters, typically hundreds or thousands like the ones showed above, and combines their results. \n",
    "\n",
    "A big argument for CNNs is that they are fast. Very fast. Convolutions are a central part of computer graphics and implemented on a hardware level on GPUs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning for Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### So, how does any of this apply to NLP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://cdn-images-1.medium.com/max/1600/0*DAcgw-fqaYq2Ppm1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### CNN Applied to NLP\n",
    "\n",
    "![](http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-06-at-12.05.40-PM.png)\n",
    "\n",
    "Source: Zhang, Y., & Wallace, B. (2015). A Sensitivity Analysis of (and Practitioners’ Guide to) Convolutional Neural Networks for Sentence Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Instead of image pixels, the input to most NLP tasks are sentences or documents represented as a matrix. Each row of the matrix corresponds to one token, typically a word, but it could be a character. That is, each row is vector that represents a word. \n",
    "\n",
    "In vision, our filters slide over local patches of an image, but in NLP we typically use filters that slide over full rows of the matrix (words). Thus, the “width” of our filters is usually the same as the width of the input matrix. The height, or region size, may vary, but sliding windows over 2-5 words at a time is typical. Putting all the above together, a Convolutional Neural Network for NLP may look like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-06-at-8.03.47-AM.png)\n",
    "\n",
    "Source: Kim, Y. (2014). Convolutional Neural Networks for Sentence Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Convolutional Filters learn good representations automatically, without needing to represent the whole vocabulary. \n",
    "\n",
    "The most natural fit for CNNs seem to be classifications tasks, such as Sentiment Analysis, Spam Detection or Topic Categorization. Convolutions and pooling operations lose information about the local order of words, so that sequence tagging as in PoS Tagging or Entity Extraction is a bit harder to fit into a pure CNN architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Labeled vs Unlabeled Data\n",
    "\n",
    "- Today, most practical, good NLP & ML methods require labeled training data (i.e., supervised learning)\n",
    "    \n",
    "    * But almost all data is unlabeled\n",
    "    \n",
    "    \n",
    "\n",
    "- Most information must be acquired unsupervised\n",
    "\n",
    "    * Fortunately, a good model of observed data can really help you learn classification decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# NLP Pipieline\n",
    "\n",
    "![](./images/nlp-pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "How do you make a computer understand that “Apple” in “Apple is a tasty fruit” is a fruit that can be eaten and not a company?\n",
    "\n",
    "The answer to the above questions lie in creating a representation for words that capture their meanings, semantic relationships and the different types of contexts they are used in.\n",
    "\n",
    "Many Machine Learning algorithms and almost all Deep Learning Architectures are incapable of processing strings or plain text in their raw form. They require numbers as inputs to perform any sort of job, be it classification, regression etc. in broad terms. And with the huge amount of data that is present in the text format, it is imperative to extract knowledge out of it and build applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Representing Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Word Embeddings\n",
    "\n",
    "![](https://deeplearning4j.org/img/word2vec_translation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "These are implemented by using Word Embeddings or numerical representations of texts so that computers may handle them. Word Embeddings are the texts converted into numbers and there may be different numerical representations of the same text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Atomic symbols\n",
    "\n",
    "    * Large vocabulary size (~1,000,000 words in English)\n",
    "    * Joint distributions impossible to infer\n",
    "    \n",
    "   ![](http://www.cse.unsw.edu.au/~billw/dictionaries/pix/parsetree.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Current NLP systems are incredibly fragile because of their atomic symbol representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Structure Corresponds to Meaning\n",
    "\n",
    "![](./images/structure-meaning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Words could be represented by Vectors\n",
    "\n",
    "- [0,0,0,0,1,0,0] \n",
    "    * Also known as \"one-hot\" representation...\n",
    "        ![](https://adeshpande3.github.io/assets/NLP8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**What is a word vector?** \n",
    "\n",
    "At one level, it’s simply a vector of weights. In a simple 1-of-N (or ‘one-hot’) encoding every element in the vector is associated with a word in the vocabulary. The encoding of a given word is simply the vector in which the corresponding element is set to one, and all other elements are zero.\n",
    "\n",
    "Using such an encoding, there’s no meaningful comparison we can make between word vectors other than equality testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Word to Vec (2013) - Word Vector Representations\n",
    "\n",
    "   - Google \n",
    "   - Publicly Available\n",
    "    ![](https://lh6.googleusercontent.com/proxy/Akd9MtQYM3jzzZQrysgNzLoawPRw_xveviWzvKXS7hxih1b-iWLA5ijHLgtP07tkMhaOOse635CKPF_cS-s4tg=w5000-h5000)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Word2vec is a group of related models that are used to produce word embeddings. These models are shallow, two-layer neural networks that are trained to reconstruct linguistic contexts of words. Word2vec takes as its input a large corpus of text and produces a vector space, typically of several hundred dimensions, with each unique word in the corpus being assigned a corresponding vector in the space. Word vectors are positioned in the vector space such that words that share common contexts in the corpus are located in close proximity to one another in the space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Principle of Word Vectorization\n",
    "\n",
    "![](./images/word-company.png)\n",
    "\n",
    "**Similar words should have similar vector representations...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](./images/coocurrance-matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In word2vec, a distributed representation of a word is used. Take a vector with several hundred dimensions (say 1000). Each word is representated by a distribution of weights across those elements. So instead of a one-to-one mapping between an element in the vector and a word, the representation of a word is spread across all of the elements in the vector, and each element in the vector contributes to the definition of many words.\n",
    "\n",
    "Such a vector comes to represent in some abstract way the ‘meaning’ of a word. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Advantages of Co-occurrence Matrix**\n",
    "\n",
    "- It preserves the semantic relationship between words. i.e man and woman tend to be closer than man and apple.\n",
    "- It uses factorization which is a well-defined problem and can be efficiently solved.\n",
    "- It has to be computed once and can be used anytime once computed. In this sense, it is faster in comparison to others.\n",
    "\n",
    "**Disadvantages of Co-Occurrence Matrix**\n",
    "\n",
    "It requires huge memory to store the co-occurrence matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://www.datascience.com/hs-fs/hubfs/Resources/Articles/nn_embed.png?t=1516924658193&width=1414&height=694&name=nn_embed.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    " Google's word2vec is one of the most widely used implementations due to its training speed and performance. Word2vec is a predictive model, which means that instead of utilizing word counts à la  latent Dirichlet allocation (LDA), it is trained to predict a target word from the context of its neighboring words. The model first encodes each word using one-hot-encoding, then feeds it into a hidden layer using a matrix of weights; the output of this process is the target word. The word embedding vectors are are actually the weights of this fitted model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Continuous Bag of Words (CBOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://adriancolyer.files.wordpress.com/2016/04/word2vec-cbow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The way CBOW work is that it tends to predict the probability of a word given a context. A context may be a single word or a group of words.\n",
    "\n",
    "The context words form the input layer. Each word is encoded in one-hot form, so if the vocabulary size is V these will be V-dimensional vectors with just one of the elements set to one, and the rest all zeros. There is a single hidden layer and an output layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Advantages of CBOW:**\n",
    "\n",
    "- Being probabilistic is nature, it is supposed to perform superior to deterministic methods(generally).\n",
    "- It is low on memory. It does not need to have huge RAM requirements like that of co-occurrence matrix where it needs to store three huge matrices.\n",
    " \n",
    "\n",
    "**Disadvantages of CBOW:**\n",
    "\n",
    "- CBOW takes the average of the context of a word (as seen above in calculation of hidden activation). For example, Apple can be both a fruit and a company but CBOW takes an average of both the contexts and places it in between a cluster for fruits and companies.\n",
    "- Training a CBOW from scratch can take forever if not properly optimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GloVe (2014) - Word Vector Representations\n",
    "\n",
    "    \n",
    "   - Stanford NLP Pipeline\n",
    "   - Publicly Available\n",
    "   \n",
    "    ![](https://nlp.stanford.edu/projects/glove/images/man_woman.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "GloVe, coined from Global Vectors, is a model for distributed word representation. The model is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Linear Relationships\n",
    "\n",
    "![](./images/word-linear-relationships.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The vectors are very good at answering analogy questions of the form a is to b as c is to ?. For example, man is to woman as uncle is to ? (aunt) using a simple vector offset method based on cosine distance.\n",
    "\n",
    "This kind of vector composition also lets us answer “King – Man + Woman = ?” question and arrive at the result “Queen” ! All of which is truly remarkable when you think that all of this knowledge simply comes from looking at lots of word in context with no other information provided about their semantics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Latest Advancements in DL & NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Visual Grounding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](./images/visual-grounding.png)\n",
    "\n",
    "Map sentences and images into a joint space..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Image Text Embedding\n",
    "\n",
    "![](./images/image-text-embedding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Image Text Generation\n",
    "\n",
    "![](http://www.stat.ucla.edu/~zyyao/projects/I2T/diagram_semanticweb.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Automatic Text Generation\n",
    "\n",
    "![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/07/Automatic-Text-Generation-Example-of-Shakespeare.png)\n",
    "\n",
    "Automatic Text Generation Example of Shakespeare\n",
    "Source: [Andrej Karpathy blog post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Computer Generated Handwriting\n",
    "\n",
    "![](./images/computer-handwriting.png)\n",
    "\n",
    "Source: [Generating Sequences With\n",
    "Recurrent Neural Networks](https://arxiv.org/pdf/1308.0850.pdf)\n",
    "\n",
    "Interactive Handwriting Generation Demo: \n",
    "http://www.cs.toronto.edu/~graves/handwriting.cgi?text=Accel+AI+Institute&style=&bias=0.15&samples=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Deep Learning Image, Video, and Audio Generation\n",
    "\n",
    "[![](https://assets.pcmag.com/media/images/547605-president-obama-lip-synced-speech-example.jpg?thumb=y&width=810&height=456)](https://youtu.be/9Yq67CjDqvw)\n",
    "\n",
    "Source: Synthesizing Obama: Learning Lip Sync from Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Questions to Ponder... \n",
    "\n",
    "- How will the law evolve to distinguish between computer & human output?\n",
    "- How will the law evolve to protect against false replications of individuals? \n",
    "- How will the law evolve to help citizens distinguish between real and fake news?\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
